{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coffee and Brimstone Notebook\n",
    "-----------------------------\n",
    "\n",
    "This notebook contains code that is used to calculate the key statistics for the \"Coffee and Brimstone\" project completed at Foundations and Applications of Humanities Analytics, July 18-22, 2022. Note that due to the probabilsitic nature of Word2Vec, exact statistics may differ between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/davidkinney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code defines all functions necessary to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(fname):\n",
    "    # Read csv file as list of lists. \n",
    "    # Then clean the list of lists \n",
    "\n",
    "    with open(fname, newline = '') as f:\n",
    "            reader = f.readlines() # read the JSON file as a Python object \n",
    "            data = reader\n",
    "\n",
    "    data = [re.sub(r'\\n|\\\\\\\\t|\\'s', '', word) for word in data] # remove line breaks, tab breaks, and possessive \"s\"\n",
    "    data = [re.sub(r'[^\\w\\s]|_', '', word) for word in data] # remove punctuation and underscore\n",
    "    data = [re.sub(r'\\d{1, 3}', '', word) for word in data] # remove digits that are a minimum of 1 and a maximum of 3\n",
    "    data = [re.sub(r'\\w*\\d\\w*', '', word) for word in data] # remove character strings that contain a digit\n",
    "        \n",
    "    data = [word.lower() for word in data]\n",
    "    data = [word.split() for word in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "def word_count(word_list, text_data):\n",
    "    # Count the words in each text.\n",
    "    counter_dict = {} # make an empty dictionary\n",
    "\n",
    "    for word in word_list: # loop through the list of words we want to look up in text\n",
    "        counter = 0 # placeholder word counter\n",
    "        for sentence in text_data: # loop through the sentences in the text\n",
    "            for text_word in sentence: # loop through individual words in each sentence in the text\n",
    "                if text_word == word:\n",
    "                    counter = counter + 1 # if the word is same as in our list, increment counter\n",
    "        counter_dict[word] = counter # update our dictionary with the word count\n",
    "        \n",
    "    return counter_dict # return the dictionary of word counts\n",
    "\n",
    "def rich_valuation(richwords,goodwords,badwords,text,model):\n",
    "    #Calculate the difference in average similarity between words associated with wealth and positively valenced words, and\\\n",
    "    #words associated with wealth and negatively valenced words. \n",
    "    richwords_total = np.sum([word_count(richwords,text)[word] for word in richwords])\n",
    "    goodwords_total = np.sum([word_count(goodwords,text)[word] for word in goodwords])\n",
    "    badwords_total = np.sum([word_count(badwords,text)[word] for word in badwords])\n",
    "    richwords_weights = [word_count(richwords,text)[word]/richwords_total  for word in richwords]\n",
    "    goodwords_weights = [word_count(goodwords,text)[word]/goodwords_total for word in goodwords]\n",
    "    badwords_weights = [word_count(badwords,text)[word]/badwords_total for word in badwords]\n",
    "    \n",
    "    return np.dot(richwords_weights,[np.dot(goodwords_weights,[model.wv.similarity(richword,goodword) for goodword in goodwords]) for richword in richwords]) -\\\n",
    "    np.dot(richwords_weights,[np.dot(badwords_weights,[model.wv.similarity(richword,badword) for badword in badwords]) for richword in richwords])\\\n",
    "    \n",
    "\n",
    "def poor_valuation(poorwords,goodwords,badwords,text,model):\n",
    "    #Calculate the difference in average similarity between words associated with poverty and positively valenced words, and\\\n",
    "    #words associated with poverty and negatively valenced words.\n",
    "    poorwords_total = np.sum([word_count(poorwords,text)[word] for word in poorwords])\n",
    "    goodwords_total = np.sum([word_count(goodwords,text)[word] for word in goodwords])\n",
    "    badwords_total = np.sum([word_count(badwords,text)[word] for word in badwords])\n",
    "    poorwords_weights = [word_count(poorwords,text)[word]/poorwords_total for word in poorwords]\n",
    "    goodwords_weights = [word_count(goodwords,text)[word]/goodwords_total for word in goodwords]\n",
    "    badwords_weights = [word_count(badwords,text)[word]/badwords_total for word in badwords]\n",
    "    \n",
    "    return np.dot(poorwords_weights,[np.dot(goodwords_weights,[model.wv.similarity(poorword,goodword) for goodword in goodwords]) for poorword in poorwords]) -\\\n",
    "    np.dot(poorwords_weights,[np.dot(badwords_weights,[model.wv.similarity(poorword,badword) for badword in badwords]) for poorword in poorwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the King James Bible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.026667942384106413, -0.09202150037075718, 0.06535355798665077]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'kjb.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "bible_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'wretched', 'least', 'beggar', 'destitute', 'poverty', 'needy', 'hungry', 'deprived', 'famished', 'indebted', 'austere']\n",
    "\n",
    "rich_words = ['rich', 'wealthy', 'gold', 'wealth', 'riches', 'ruler', 'fat', 'prosperous', 'lavish', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'virtuous', 'devout', 'valued', 'clean', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'covet', 'oppress', 'smite', 'inferior', 'evil', 'thieves', 'sinful', 'unholy']\n",
    "\n",
    "bible_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,bible_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,bible_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,bible_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,bible_model)]\n",
    "bible_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Siri Guru Granth Sahib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'siri.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "siri_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'wretched', 'least', 'beggar', 'destitute', 'poverty', 'pauper', 'unfortunate', 'needy', 'hungry', 'homeless', 'deprived', 'austere', 'ascetic']\n",
    "\n",
    "rich_words = ['rich', 'wealthy', 'gold', 'wealth', 'riches', 'ruler', 'prosperous', 'dynasty', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'virtuous', 'pious', 'superior', 'valued', 'clean', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'covet', 'oppress', 'exploit', 'immoral', 'inferior', 'evil', 'thieves', 'sinful', 'dirty', 'impure']\n",
    "\n",
    "siri_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,siri_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,siri_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,siri_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,siri_model)]\n",
    "siri_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Kojiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Kojiki_Horne.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "koji_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['least']\n",
    "\n",
    "rich_words = ['ruler', 'jeweled']\n",
    "\n",
    "good_words = ['good', 'pure']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'smite', 'evil']\n",
    "\n",
    "koji_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,koji_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,koji_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,koji_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,koji_model)]\n",
    "koji_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Quran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Quran.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "quran_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'wretched', 'least', 'beggar', 'destitute', 'poverty', 'unfortunate', 'needy', 'hungry', 'deprived']\n",
    "\n",
    "rich_words = ['rich', 'wealthy', 'affluent', 'gold', 'wealth', 'riches', 'ruler', 'fat', 'luxury', 'luxurious', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'virtuous', 'pious', 'devout', 'superior', 'clean', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'covet', 'oppress', 'smite', 'evil', 'thieves', 'sinful', 'repentant']\n",
    "\n",
    "quran_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,quran_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,quran_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,quran_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,quran_model)]\n",
    "quran_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Upanishads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Upanishads'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "upanishads_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['least']\n",
    "\n",
    "rich_words = ['rich', 'gold', 'wealth', 'ruler', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'pious', 'superior', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'covet', 'inferior', 'evil', 'impure']\n",
    "\n",
    "\n",
    "upanishads_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,upanishads_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,upanishads_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,upanishads_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,upanishads_model)]\n",
    "upanishads_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Popul Vuh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Popul_Vuh'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "popul_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'least', 'hungry']\n",
    "\n",
    "rich_words = ['wealthy', 'ruler']\n",
    "\n",
    "good_words = ['good', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'evil']\n",
    "\n",
    "popul_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,popul_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,popul_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,popul_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,popul_model)]\n",
    "popul_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Bhagavad Gita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Bhagavad-Gita', 'r') as f:\n",
    "     page_content = BeautifulSoup(f, 'html.parser').find_all('p')\n",
    "\n",
    "data = []\n",
    "for paragraph in page_content: # do some additional cleaning. For each paragraph, \"strip\" the strings (i.e. get rid of anchors left over from the HTML)\n",
    "    data.extend(paragraph.stripped_strings)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "bg_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['least', 'beggar', 'deprived']\n",
    "\n",
    "rich_words = ['rich', 'gold', 'wealth', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'pious', 'devout', 'superior', 'clean', 'holy', 'glorious', 'pure']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'evil', 'sinful']\n",
    "\n",
    "\n",
    "bg_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,bg_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,bg_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,bg_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,bg_model)]\n",
    "bg_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Dao De Jing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dao_De_Jing_html', 'r') as f:\n",
    "     page_content = BeautifulSoup(f, 'html.parser').find_all('p')\n",
    "\n",
    "data = []\n",
    "for paragraph in page_content: # do some additional cleaning. For each paragraph, \"strip\" the strings (i.e. get rid of anchors left over from the HTML)\n",
    "    data.extend(paragraph.stripped_strings)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "ddj_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['least']\n",
    "\n",
    "rich_words = ['gold', 'wealth', 'ruler']\n",
    "\n",
    "good_words = ['good', 'virtuous', 'moral', 'superior', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'inferior', 'evil', 'thieves']\n",
    "\n",
    "ddj_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,ddj_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,ddj_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,ddj_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,ddj_model)]\n",
    "ddj_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Zend Avesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'zend_avesta.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "zend_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'wretched', 'least', 'poverty', 'unfortunate', 'deprived', 'indebted']\n",
    "\n",
    "rich_words = ['rich', 'wealthy', 'affluent', 'gold', 'wealth', 'riches', 'ruler', 'fat', 'prosperous', 'dynasty', 'exorbitant']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'virtuous', 'pious', 'devout', 'orthodox', 'moral', 'superior', 'valued', 'clean', 'ethical', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'oppress', 'immoral', 'smite', 'inferior', 'evil', 'bandits', 'thieves', 'sinful', 'unholy', 'impure']\n",
    "\n",
    "zend_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,zend_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,zend_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,zend_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,zend_model)]\n",
    "zend_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code calculates all revelavant statistics for the Tanakh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Tanakh1917.txt'\n",
    "data = data_import(fname)\n",
    "stop_words = stopwords.words('english')\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "tanakh_model = gensim.models.Word2Vec(sentences = data_words, workers = 8, min_count = 0, vector_size = 100) \n",
    "\n",
    "poor_words = ['poor', 'least', 'destitute', 'poverty', 'unfortunate', 'needy', 'hungry', 'deprived', 'famished']\n",
    "\n",
    "rich_words = ['rich', 'gold', 'wealth', 'riches', 'ruler', 'fat', 'prosperous', 'lavish', 'abundance']\n",
    "\n",
    "good_words = ['good', 'blessed', 'righteous', 'virtuous', 'valued', 'clean', 'holy', 'glorious', 'pure', 'proper']\n",
    "\n",
    "bad_words = ['bad', 'woe', 'covet', 'oppress', 'smite', 'inferior', 'evil', 'thieves', 'sinful', 'impure']\n",
    "\n",
    "tanakh_stats = [rich_valuation(rich_words,good_words,bad_words,data_words,tanakh_model),\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,tanakh_model),\\\n",
    "               rich_valuation(rich_words,good_words,bad_words,data_words,tanakh_model)-\\\n",
    "               poor_valuation(poor_words,good_words,bad_words,data_words,tanakh_model)]\n",
    "tanakh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
